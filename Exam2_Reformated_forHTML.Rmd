---
title: "Exam2_Testfile_update"
output:
  html_document: default
  html_notebook: default
---
# Exam 2
### Jaleel Jefferson, Ksenia Vlasov, and Emily Davis

```{r}
knitr::opts_chunk$set(echo = TRUE)

#Setting working directory and loading necessary libraries
setwd("/Users/jalee/Documents/rfiles/")
library(tidyverse)
library(boot)
library(pwr)
s
## Loading and Exploring Data
#1
#loading txt files
logRPKM <- read.table("NSC219_scRNA_logRPKM.txt")
Metadata <- read.table("NSC219_scRNA_Metadata.txt", header=TRUE)
merged <- read.table("NSC219_scRNA_merged.txt")

#checking data type
head(logRPKM)
head(Metadata)
head(merged)

#2a
#Making summary tables of Enhancer types vs Region/Phase/Cluster
sumEnhancerRegion <- table(Metadata$Enhancer, Metadata$Region)
sumEnhancerPhase <- table(Metadata$Enhancer, Metadata$Phase)
sumEnhancerCluster <- table(Metadata$Enhancer, Metadata$Cluster)
#Displaying Sample Enhancer vs Phase Summary Table
sumEnhancerPhase

#2b
#Placing LogRPKM values of selected genes in their own Values
Dcx <- merged$ENSMUSG00000031285.Dcx
Nkx2.1 <- merged$ENSMUSG00000001496.Nkx2.1
Actb <- merged$ENSMUSG00000029580.Actb

#BaseR Boxplot of LogRPKM values
boxplot(Dcx, Nkx2.1, Actb, main="Value Distribution Boxplot", names=c("Dcx", "Nkx2.1", "Actb"), notch=FALSE)

#BaseR Boxplots of LogRPKM values
par(mfrow=c(1,3))
hist(Dcx)
hist(Nkx2.1)
hist(Actb)


#2c: Description of distributions  
#The Dcx histogram appears bimondal and the Nkx2.1 histogram appears skewed. The Actb histogram appears normal, though the boxplot shows many outliers.

# Inference for Categorical Data  

#3a: Null Hypothesis: Enhancer classes 192-Pos and 799-Pos are not biased towards post-mitotic phase.

#3b
#Sorting out Enhancer classes 192-Pos and 799-Pos from sumEnhancerPhase table
subset.sumEP <- sumEnhancerPhase[2:3,1:2]
#Summing the columns from subset.sumEP
observed <- colSums(subset.sumEP)
#Summing the total observations
total <- sum(observed)
#Generating an expected table based on a 50/50 distribuition between either class as half of the total observations
expected <- c(total/2, total/2)

#Printing contingency table to be input into the chisq.test function
rbind(observed,expected)
chisq.test(rbind(observed,expected))

#3c
#Chisq.test function with monte carlo simulation, 2000 replicates
chisq.test(rbind(observed,expected), simulate.p.value=T, B=2000)

#3d: Discussion of results:  
#Both p-values are sufficiently low to reject the null hypothesis that enhancers are not biased towards a phase.  
#For 3b: p-value=2.2e-16  
#For 3c: p-value=0.0004998  
#Therefore, can accept the alternative hypothesis there is a bias towards the a phase  
  
#4a: Null Hypothesis: Enhancer classes 192 and 799 have the same bias between mitotic and postmitotic phases

#4b
#Printing contingency table to be input into chisq.test
subset.sumEP
chisq.test(subset.sumEP)

#4c
#Chisq.test function with monte carlo simulation, 2000 replicates
chisq.test(subset.sumEP,simulate.p.value=T, B=2000)

#4d: Discussion of results:  
#For 4b: pvalue= 0.285  
#For 4c: pvalue= 0.2714  
#These p values are high enough that we cannot reject the null hypothesis. Therefore enhancer classes 192 and 799 have the same bias towards the postmitotic phase.  
  
#5a: Null Hyptothesis: Enhancer classes 1056-Pos and 799-Pos have the same bias between mitotic and postmitotic phases

#5b
#Sorting out Enhancer classes 1056-Pos and 799-Pos from sumEnhancerPhase table
fivesubset.sumEP <- sumEnhancerPhase[c(1,3),1:2]
#Printing contingency table to be input into chisq.test
fivesubset.sumEP
chisq.test(fivesubset.sumEP)

#5c
#Chisq.test function with monte carlo simulation, 2000 replicates
chisq.test(fivesubset.sumEP,simulate.p.value=T, B=2000)

#5d: Discussion of results:  
#For 5b: pvalue= 2.2e-16  
#For 5c: pvalue= 0.0004998  
#These p values are low enough that we can reject the null hypothesis. Therefore enhancer classes 1056 and 799 have different biases towards the mitotic and postmitotic phases.

# Inference for Continuous Data

#6a
#Separating MGE and LGE regions into their own data frames from the merged file
MGE.merged <- filter(merged, Region=="MGE")
LGE.merged <- filter(merged, Region=="LGE")
#Calculating mean based on Region
meanMGE <- mean(MGE.merged$ENSMUSG00000001496.Nkx2.1)
meanLGE <- mean(LGE.merged$ENSMUSG00000001496.Nkx2.1)
#Calculating standard deviation based on Region
sdMGE <- sd(MGE.merged$ENSMUSG00000001496.Nkx2.1)
sdLGE <- sd(LGE.merged$ENSMUSG00000001496.Nkx2.1)
#Displaying mean and standard deviations
meanMGE
meanLGE
sdMGE
sdLGE

#6b
#Loading boot.statistic given in SourceFunction code
boot.statistic <- function(my.data, indices) {
  return(mean(my.data[indices]))
}

#Printing a heading
print("Bootstrapping of MGE")
#Running bootstrapping from boot library on Nkx2.1 gene in MGE region, using mean as boot.statistic with 100 reps
boot.results <- boot(MGE.merged$ENSMUSG00000001496.Nkx2.1, statistic=boot.statistic, R=10000)
print(boot.results)
#Running 95% confidence interval function from boot library based on boot.results
boot.ci(boot.results, conf=0.95, type="basic")
#CI: 2.553-3.094

#Printing a heading
print("Bootstrapping of LGE")
#Running bootstrapping from boot library on Nkx2.1 gene in LGE region, using mean as boot.statistic with 100 reps
boot.results <- boot(LGE.merged$ENSMUSG00000001496.Nkx2.1, statistic=boot.statistic, R=10000)
print(boot.results)
#Running 95% confidence interval function from boot library based on boot.results
boot.ci(boot.results, conf=0.95, type="basic")
#CI: 0.0027-0.06938985

#6c
#Making a data frame of Region and Nkx2.1 LogRPKM values for plotting purposes
subset.Region.Nkx2.1 <- filter(merged, Region==c("MGE", "LGE"))
Region.Nkx2.1 <- data.frame(subset.Region.Nkx2.1$Region, subset.Region.Nkx2.1$ENSMUSG00000001496.Nkx2.1)
#Naming columns for easy recall in ggplot
colnames(Region.Nkx2.1) <- c("Region", "Nkx2.1")
#ggplot boxplot of Nkx2.1 LogRPKM values based on region
boxplotNkx2.1 <- ggplot(Region.Nkx2.1) +
  geom_boxplot(aes(x=Region, y=Nkx2.1)) +
  geom_point(aes(x=Region, y=Nkx2.1)) +
  labs(x="Region", y="logRPKM", title="Nkx2.1 logRPKM values by Region") +
  theme_bw() + 
  theme(plot.title=element_text(hjust = 0.5 ))
boxplotNkx2.1

#6d
#Null Hypothesis: Cells from the MGE and LGE regions do not differ in Nkx2.1 logRPKM values

#6e
#T.test of Nkx2.1 logRPKM values in MGE vs LGE regions
t.test(MGE.merged$ENSMUSG00000001496.Nkx2.1, LGE.merged$ENSMUSG00000001496.Nkx2.1)

#6f
#wilcoxon test of Nkx2.1 logRPKM values in MGE vs LGE regions
wilcox.test(MGE.merged$ENSMUSG00000001496.Nkx2.1, LGE.merged$ENSMUSG00000001496.Nkx2.1)


##Prewritten Permutation Function provided in SourceFunction code
permuteCont <- function(data1, data2, useCenter = "median", reps) {
  # initiate values and figure out counts for groups
  obs.tstat <- NA
  tstat.output <- rep(NA, length = reps)
  group1.count <- length(data1)
  group2.count <- length(data2)
  all.data <- c(data1, data2)
  # start a for loop with number of interations equal to desired reps  
  for (rep.count in 1:reps) { 
    # first randomly assign group matching counts
    temp.group <- rep(NA, length = length(all.data))
    # randomly sample from total number of elements in all data, assign group1
    group1.shuffle <- sample(1:length(all.data), size = group1.count)
    temp.group[group1.shuffle] <- 1
    # all the rest are group2    
    temp.group <- ifelse(is.na(temp.group),2,1)
    # then compute center and find test statistic of difference using mean or median
    if (useCenter == "mean") {
      group1.value <- mean(all.data[which(temp.group==1)])
      group2.value <- mean(all.data[which(temp.group==2)])
      tstat.output[rep.count] <- (group1.value - group2.value)
    }
    if (useCenter == "median") {
      group1.value <- median(all.data[which(temp.group==1)])
      group2.value <- median(all.data[which(temp.group==2)])
      tstat.output[rep.count] <- (group1.value - group2.value)
    }
  }
  # calculate observed and emprirical p-value using mean or median
  if (useCenter == "mean") {
    group1.value <- mean(data1)
    group2.value <- mean(data2)
    obs.tstat <- (group1.value - group2.value)
  }
  if (useCenter == "median") {
    group1.value <- median(data1)
    group2.value <- median(data2)
    obs.tstat <- (group1.value - group2.value)
  }
  # calculate empirical p based on which shuffled tstats are equal or more extreme vs obs
  empirical.p <- sum(abs(tstat.output) >= abs(obs.tstat))/reps
  # plot observed vs. empirical null
  min.x <- ifelse(min(tstat.output)<obs.tstat,min(tstat.output),obs.tstat)
  max.x <- ifelse(max(tstat.output)>obs.tstat,max(tstat.output),obs.tstat)
  hist(tstat.output, col="grey", xlab="empirical null stat values", main="Emprical Null Histogram", xlim=c(min.x, max.x))
  abline(v=obs.tstat, col="red", lwd=4)
  # return a list with obs.stat, empirical p-value (two-tailed), permuted tstats
  return(list(obs.tstat, empirical.p, tstat.output))
}

#6g
#Running permutation function on Nkx2.1 logRPKM values in MGE vs LGE regions based on median differences with 10,000 replicates
permut.output.median <- permuteCont(MGE.merged$ENSMUSG00000001496.Nkx2.1, LGE.merged$ENSMUSG00000001496.Nkx2.1,useCenter = "median", 10000)
permut.output.median[2]

#Running permutation function on Nkx2.1 logRPKM values in MGE vs LGE regions based on mean differences with 10,000 replicates
permut.output.mean <- permuteCont(MGE.merged$ENSMUSG00000001496.Nkx2.1, LGE.merged$ENSMUSG00000001496.Nkx2.1,useCenter = "mean", 10000)
permut.output.mean[2]

#6h:  
#The original distributions were highly skewed. After permutation, empirical null values for both median and mean show normal distributions that can be run through parametric statistics. The empirical p value in both cases is 0. Therefore we can reject the null hypothesis that the logRPKM value did not differ between regions in favor of saying there is a difference.

# Multiple Testing Burden and Correction
#7a
#generating an empty vector to store p Values within
pval <- vector()

#For loop calling columns in region.merged files for all genes
for (gene in 6:33) {
  #Running permutation fucntion on logRPKM values in MGE vs LGE regions for each of 28 genes individually based on mean differences (default) with 1,000 replicates and storing output in 'holding' variable
  holding <- permuteCont(MGE.merged[,gene], LGE.merged[,gene], reps=10000)
  #Storing pvalue(the second in 'holding' list) within pval vector
  pval <- append(pval, holding[2])
}

#7b
#Adjusting pvalues using Bonferroni method
bon.pval <- p.adjust(pval, method="bonferroni")

#7c
#Adjusting pvalues using BH (Behnjamini Hochberg) method
BH.pval <- p.adjust(pval, method="BH")

#7d
#Collecting corrected bonferroni and BH pvalues in a data frame
adjustedpval <- data.frame(bon.pval,BH.pval)
#Plotting corrected pvalues in ggplot scatterplot (geom_point)
adjustedpplot <- ggplot(adjustedpval)+
  geom_point(aes(x=bon.pval, y=BH.pval))+
  labs(x="Bonferroni", y="Hochberg", title="Bonferroni versus BH: Adjusted P-values")
adjustedpplot

#7e  
#Of the twelve p-value, about half are below 0.05 when BH corrected and only one is below 0.05 when Bonferroni corrected. This shows that Bonferroni is a quite strigent correction method.


# Power Analysis
#8a
#Loading cohen's d calculation function from SourceFunction code
simple.d <- function(mean1, mean2, sd1, sd2, n1, n2) {
  mean.diff <- abs(mean1 - mean2)
  if (abs(n1 - n2) <= n1/10) {
  pooled.sd <- sqrt((sd1^2 + sd2^2)/2)  
  }
  if (abs(n1 - n2) > n1/10) {
  pooled.sd <- sqrt((((n1-1)*sd1^2) + ((n2-1)*sd2^2))/(n1 + n2 - 2))  
  }
  d <- mean.diff / pooled.sd
  return(d)
} 

#Caculating cohen's d from Nkx2.1 logRPKM values in MGE and LGE regions, calling each mean and sd and sample number individually
d.Nkx2.1 <- simple.d(mean(MGE.merged$ENSMUSG00000001496.Nkx2.1), mean(LGE.merged$ENSMUSG00000001496.Nkx2.1), sd(MGE.merged$ENSMUSG00000001496.Nkx2.1), sd(LGE.merged$ENSMUSG00000001496.Nkx2.1), length(MGE.merged$ENSMUSG00000001496.Nkx2.1), length(LGE.merged$ENSMUSG00000001496.Nkx2.1))
d.Nkx2.1

#8b
#Running pwr.t.test to determing sample size needed to reach 80% power and cohen's d value from 8a
pwr.t.test(d=d.Nkx2.1,sig.level=0.05,power=.8, type="two.sample", alternative="two.sided")

#8c
#Storing Cohen's d values in a variable
d.list <- c(0.2, 0.5, 0.8, d.Nkx2.1)
#Storing sample sizes in a variable
n.list <- c(10,50,100,500,1000)
#Generating empty matrix to store pwr values within
pwr.matrix <- matrix(nrow=5, ncol=4)

#Establishing a counter of Cohen's d value at 0
dcount=0

#For loop for every cohen's d value
for (d in d.list){
  #add one to cohen's d counter
  dcount=dcount+1
  #Establishing a counter of sample size value at 0
  ncount=0
  #Nested for loop for every sample size value
  for (n in n.list){
    #add one to sample size counter
    ncount=ncount+1
    #Running t.test power analysis on given cohen's d and sample size based on for loops and saving power output
    pwr <- pwr.t.test(n=n, d=d,sig.level=0.05, type="two.sample", alternative="two.sided")$power
    #Saving power output within pwr matrix based on sample size and cohen's d counters
    pwr.matrix[ncount,dcount] <- pwr
  }
}

#Creating a data frame of sample sizes and pwr values from power matrix
pwr.df <- data.frame(n.list, pwr.matrix)
#Plotting pwr curve from pwr.df data frame, calling each cohen d value by column name (ie X2/X2/X3/X4)
pwr.plot <- ggplot(pwr.df)+
  geom_line(aes(x=n.list, y=X1, color="0.2"))+
  geom_line(aes(x=n.list, y=X2, color="0.5"))+
  geom_line(aes(x=n.list, y=X3, color= "0.8"))+
  geom_line(aes(x=n.list, y=X4, color= "1.469"))+
  labs(x="Sample Size", y="Power", title="Power Curve Plot")+
  #Manually creating color scheme and Legend Titles
  scale_color_manual(name="Cohen's d", values=c("red1", "blue1", "green4", "purple1"))
pwr.plot

#8d  
#Interpretation of Results: With greater Cohen's d values (a combination of effect size and sample variance), smaller sample sizes are needed to reach sufficient statistical power.
```



